# ğŸš€ SalesDataPipline-DataMart-Project

This Data Engineering aims to provide you with insights into the functioning of projects within a real-time environment.

- ğŸ“Š Data will be pulled from upstream (Amazon S3) and then downloaded to on-premise (local) and processed using the business logic.
- ğŸ’¼ Processed data will be written into Customer and Sales Datamart in MySQL Table in the warehouse. For the same data, partitioned parquet will be generated and uploaded to Amazon S3.
- ğŸ“ˆ Downstream and reporting teams can access datamart tables and can also use parquet files provided on the Amazon S3 bucket for analysis.
- ğŸ­ This project aims to replicate the production environment so includes features like audit-table, archiving of processed data, schema validation of the files, handling extra and less column, detecting the wrong format file, logging, encrypting, and decrypting access and secret, etc.
- ğŸ’¡ Business logic like customer total sales by month, giving incentives to top salesman, etc.

The code has been meticulously crafted with careful consideration for various aspects. It not only nurtures your coding skills but also imparts a comprehensive comprehension of project structures.

## Requirements:

- ğŸ’» Laptop with minimum 4 GB of RAM, i3 and above (Better to have 8GB with i5).
- ğŸŒŸ Local setup of Spark.
- ğŸ–¥ï¸ PyCharm installed on the system.
- ğŸ“Š MySQL Workbench should also be installed on the system.
- ğŸ“¦ GitHub account is good to have but not necessary.
- â˜ï¸ AWS account.
- ğŸ§  Understanding of Spark, SQL, and Python is required.


## Project Structure:
          my_project
           â”œâ”€â”€ docs
           â”‚   â””â”€â”€ readme.md
           â”œâ”€â”€ resources
           â”‚   â”œâ”€â”€ init.py
           â”‚   â”œâ”€â”€ dev
           â”‚   â”‚   â”œâ”€â”€ config.py
           â”‚   â”‚   â””â”€â”€ requirement.txt
           â”‚   â”œâ”€â”€ qa
           â”‚   â”‚   â”œâ”€â”€ config.py
           â”‚   â”‚   â””â”€â”€ requirement.txt
           â”‚   â”œâ”€â”€ prod
           â”‚   â”‚   â”œâ”€â”€ config.py
           â”‚   â”‚   â””â”€â”€ requirement.txt
           â”‚   â””â”€â”€ sql_scripts
           â”‚       â””â”€â”€ table_scripts.sql
           â””â”€â”€ src
               â”œâ”€â”€ main
               â”‚   â”œâ”€â”€ init.py
               â”‚   â”œâ”€â”€ delete
               â”‚   â”‚   â”œâ”€â”€ aws_delete.py
               â”‚   â”‚   â”œâ”€â”€ database_delete.py
               â”‚   â”‚   â””â”€â”€ local_file_delete.py
               â”‚   â”œâ”€â”€ download
               â”‚   â”‚   â””â”€â”€ aws_file_download.py
               â”‚   â”œâ”€â”€ move
               â”‚   â”‚   â””â”€â”€ move_files.py
               â”‚   â”œâ”€â”€ read
               â”‚   â”‚   â”œâ”€â”€ aws_read.py
               â”‚   â”‚   â””â”€â”€ database_read.py
               â”‚   â”œâ”€â”€ transformations
               â”‚   â”‚   â””â”€â”€ jobs
               â”‚   â”‚       â”œâ”€â”€ customer_mart_sql_transform_write.py
               â”‚   â”‚       â”œâ”€â”€ dimension_tables_join.py
               â”‚   â”‚       â”œâ”€â”€ main.py
               â”‚   â”‚       â””â”€â”€ sales_team_mart_sql_transformation_write.py
               â”‚   â”œâ”€â”€ upload
               â”‚   â”‚   â””â”€â”€ upload_to_s3.py
               â”‚   â””â”€â”€ utility
               â”‚       â”œâ”€â”€ encrypt_decrypt.py
               â”‚       â”œâ”€â”€ logging_config.py
               â”‚       â”œâ”€â”€ s3_client_object.py
               â”‚       â”œâ”€â”€ spark_session.py
               â”‚       â””â”€â”€ my_sql_session.py
               â””â”€â”€ test
                   â”œâ”€â”€ scratch_pad.py.py
                   â”œâ”€â”€ generate_csv_data.py
                   â”œâ”€â”€ extra_column_csv_generated_data.py
                   â”œâ”€â”€ generate_customer_table_data.py
                   â”œâ”€â”€ generate_datewise_sales_data.py
                   â”œâ”€â”€ less_column_csv_generated_data.py
                   â”œâ”€â”€ mysql_table_to_dataframe.py
                   â””â”€â”€ sales_data_upload_s3.py


## How to run the program in PyCharm:

1. ğŸš€ Open the PyCharm editor.
2. ğŸ“‚ Upload or pull the project from GitHub.
3. ğŸ–¥ï¸ Open the terminal from the bottom pane.
4. ğŸ› ï¸ Go to the virtual environment and activate it. Let's say you have venv as a virtual environment.
    - `cd venv`
    - `cd Scripts`
    - `activate` (if activate doesn't work then use ./activate)
5. ğŸ”‘ You will have to create a user on AWS also and assign S3 full access and provide a secret key and access key to the config file.
6. â–¶ï¸ Run main.py from the green play button on the top right-hand side.


